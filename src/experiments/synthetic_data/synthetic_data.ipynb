{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Synthetic Data using a formulation of the Swing-Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'src' as root folder, to find other modules in the project\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# local imports\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimulator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Swing_5_Equation, Swing_4_Equation\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# external imports\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/kit/iai/ik6649/Data-Driven-Bayesian-Parameter-Estimation-with-Neural-Networks-1/src/experiments/synthetic_data/../../simulator/simulator.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimulator\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# local imports\n",
    "from simulator.simulator import Swing_5_Equation, Swing_4_Equation\n",
    "\n",
    "# external imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sbi.inference import SNPE, SNRE, SNLE, simulate_for_sbi, prepare_for_sbi\n",
    "from sbi.utils import posterior_nn, BoxUniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "Different Swing Equation formulations using Euler Maruyama to solve.\n",
    "These are just formulations using different parameters describing power grid dynamics with different precision.\n",
    "In this case the 5 Parameter model should model the frequency dynamics more precise.\n",
    "\n",
    "1. 4 Parameter Model ``Swing_4_Equation``:\n",
    "\n",
    "    $\\frac{d\\omega}{dt} = c_1\\omega + c_2\\Theta + P_{const} + \\epsilon\\xi$\n",
    "2. 5 Parameter Model ``Swing_5_Equation``:\n",
    "    \n",
    "    $\\frac{d\\omega}{dt} = c_1\\omega + c_2\\Theta + P_0 + P_1t + \\epsilon\\xi$\n",
    "\n",
    "For a more detailed explanation, analysis and proposal of the Equations make sure to read (Artikel verlinken), or view the experiment [notebook](swing_equation_parameter.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Parameter Model assumption on true values for theta\n",
    "# - tensor(c_1, c_2, P_const, epsilon)\n",
    "theta_true_4 = torch.tensor([0.5, 0.5, 0.1, 0.05])\n",
    "\n",
    "# 5 Parameter Model assumption on true values for theta\n",
    "# - tensor(c_1, c_2, P_0, P_1, epsilon)\n",
    "theta_true_5 = torch.tensor([4.0, 40.0, 3.0, 60.0, 7.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training Parameters\n",
    "\n",
    "1. [Simulation Parameters](#simulation-parameters)\n",
    "2. [Neural Density Estimator Parameters](#neural-density-estimator-parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the simulation parameters\n",
    "# Define length and timesteps of the simulations\n",
    "dt = 0.01\n",
    "T = 10\n",
    "\n",
    "# Define 2 simulators with different model precision\n",
    "simulator_4 = Swing_4_Equation(dt=dt, T=T)\n",
    "simulator_5 = Swing_5_Equation(dt=dt, T=T)\n",
    "\n",
    "# Define proposals for parameter distributions\n",
    "\n",
    "# Modify proposal to be a uniform distribution with possible parameter values\n",
    "proposal_low_5 = torch.tensor([0.1, 1.0, 0.1, 40.0, 0.1])\n",
    "proposal_high_5 = torch.tensor([10.0, 100.0, 10.0, 70.0, 10.0])\n",
    "proposal_5 = BoxUniform(low=proposal_low_5, high=proposal_high_5)\n",
    "\n",
    "# Define proposal for the 4-parameter model as a uniform distribution\n",
    "proposal_low_4 = torch.tensor([0.1, 0.1, 0.01, 0.01])\n",
    "proposal_high_4 = torch.tensor([1.0, 1.0, 0.5, 0.1])\n",
    "proposal_4 = BoxUniform(low=proposal_low_4, high=proposal_high_4)\n",
    "\n",
    "# # Define proposal for the 4-parameter model as a normal distribution\n",
    "# proposal_means_4 = torch.tensor([0.5, 0.5, 0.1, 0.05])\n",
    "# proposal_stddevs_4 = torch.tensor([0.1, 0.1, 0.05, 0.01])\n",
    "# proposal_means_4 = torch.max(proposal_means_4, torch.tensor(1e-6))\n",
    "\n",
    "# # Create a truncated normal distribution centered around proposal_means with standard deviations\n",
    "# proposal_4 = TruncatedNormal(\n",
    "#     loc=proposal_means_4, \n",
    "#     scale=proposal_stddevs_4,\n",
    "#     min=torch.tensor([0.1, 0.1, 0.01, 0.01]), \n",
    "#     max=torch.tensor([1.0, 1.0, 0.5, 0.1]) \n",
    "# )\n",
    "\n",
    "# # Define proposal for the 5-parameter model\n",
    "# proposal_means_5 = torch.tensor([4.0, 40.0, 3.0, 60.0, 7.0])\n",
    "# proposal_stddevs_5 = torch.tensor([1.0, 5.0, 1.0, 5.0, 1.0])\n",
    "# proposal_means_5 = torch.max(proposal_means_5, torch.tensor(1e-6))\n",
    "\n",
    "# # Create a truncated normal distribution centered around proposal_means with standard deviations\n",
    "# proposal_5 = TruncatedNormal(\n",
    "#     loc=proposal_means_5, \n",
    "#     scale=proposal_stddevs_5,\n",
    "#     min=torch.tensor([0.1, 1.0, 0.1, 40.0, 0.1]),  \n",
    "#     max=torch.tensor([10.0, 100.0, 10.0, 70.0, 10.0])\n",
    "# )\n",
    "\n",
    "# Define simulation process parameters\n",
    "num_simulations = 20000\n",
    "num_workers = 20\n",
    "simulation_batch_size = 50\n",
    "seed = None\n",
    "show_progress_bar = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Density Estimator Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density estimator parameters\n",
    "model = 'maf'\n",
    "hidden_features = 50\n",
    "num_transforms = 10\n",
    "z_score_x = 'independent'\n",
    "z_score_theta = 'independent'\n",
    "num_bins = 10\n",
    "num_components = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the simulator function for compatibility with SBI\n",
    "post_simulator_4, proposal_4 = prepare_for_sbi(simulator_4.simulate, proposal_4)\n",
    "post_simulator_5, proposal_5 = prepare_for_sbi(simulator_5.simulate, proposal_5)\n",
    "\n",
    "# Run the inference procedure to generate samples and corresponding simulated data points\n",
    "theta_4, x_4 = simulate_for_sbi(\n",
    "    simulator=post_simulator_4, \n",
    "    proposal=proposal_4, \n",
    "    num_simulations=num_simulations, \n",
    "    num_workers=num_workers, \n",
    "    simulation_batch_size=simulation_batch_size, \n",
    "    seed=seed, \n",
    "    show_progress_bar=show_progress_bar\n",
    ")   \n",
    "\n",
    "theta_5, x_5 = simulate_for_sbi(\n",
    "    simulator=post_simulator_5, \n",
    "    proposal=proposal_5, \n",
    "    num_simulations=num_simulations, \n",
    "    num_workers=num_workers, \n",
    "    simulation_batch_size=simulation_batch_size, \n",
    "    seed=seed, \n",
    "    show_progress_bar=show_progress_bar\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default observation by simulating the true parameters\n",
    "default_observation_4 = simulator_4.simulate(theta_true_4)\n",
    "default_observation_5 = simulator_5.simulate(theta_true_5)\n",
    "\n",
    "# # Instantiate the neural density estimator\n",
    "# neural_posterior_4 = posterior_nn(\n",
    "#     model=model, \n",
    "#     hidden_features=hidden_features, \n",
    "#     num_transforms=num_transforms, \n",
    "#     num_bins=num_bins, \n",
    "#     num_components=num_components, \n",
    "#     z_score_theta=z_score_theta, \n",
    "#     z_score_x=z_score_x\n",
    "# )\n",
    "\n",
    "# neural_posterior_5 = posterior_nn(\n",
    "#     model=model, \n",
    "#     hidden_features=hidden_features, \n",
    "#     num_transforms=num_transforms, \n",
    "#     num_bins=num_bins, \n",
    "#     num_components=num_components, \n",
    "#     z_score_theta=z_score_theta, \n",
    "#     z_score_x=z_score_x\n",
    "# )\n",
    "\n",
    "# # Set up the inference procedure with the SNPE procedure\n",
    "# inference_4 = SNPE(prior=proposal_4, density_estimator=neural_posterior_4)\n",
    "# inference_5 = SNPE(prior=proposal_5, density_estimator=neural_posterior_5)\n",
    "\n",
    "inference_4_snpe = SNPE(prior=proposal_4)\n",
    "inference_5_snpe = SNPE(prior=proposal_5)\n",
    "\n",
    "inference_4_snle = SNLE(prior=proposal_4)\n",
    "inference_5_snle = SNLE(prior=proposal_5)\n",
    "\n",
    "inference_4_snre = SNRE(prior=proposal_4)\n",
    "inference_5_snre = SNRE(prior=proposal_5)\n",
    "\n",
    "# Train the neural density estimator\n",
    "density_estimator_4_snpe = inference_4_snpe.append_simulations(theta_4, x_4).train()\n",
    "density_estimator_5_snpe = inference_5_snpe.append_simulations(theta_5, x_5).train()\n",
    "\n",
    "density_estimator_4_snle = inference_4_snle.append_simulations(theta_4, x_4).train()\n",
    "density_estimator_5_snle = inference_5_snle.append_simulations(theta_5, x_5).train()\n",
    "\n",
    "density_estimator_4_snre = inference_4_snre.append_simulations(theta_4, x_4).train()\n",
    "density_estimator_5_snre = inference_5_snre.append_simulations(theta_5, x_5).train()\n",
    "\n",
    "# Build the posterior for the given parameters\n",
    "posterior_4_snpe = inference_4_snpe.build_posterior(density_estimator_4_snpe).set_default_x(default_observation_4)\n",
    "posterior_5_snpe = inference_5_snpe.build_posterior(density_estimator_5_snpe).set_default_x(default_observation_5)\n",
    "\n",
    "posterior_4_snle = inference_4_snle.build_posterior(density_estimator_4_snle).set_default_x(default_observation_4)\n",
    "posterior_5_snle = inference_5_snle.build_posterior(density_estimator_5_snle).set_default_x(default_observation_5)\n",
    "\n",
    "posterior_4_snre = inference_4_snre.build_posterior(density_estimator_4_snre).set_default_x(default_observation_4)\n",
    "posterior_5_snre = inference_5_snre.build_posterior(density_estimator_5_snre).set_default_x(default_observation_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "- [Statistical, Theoretical Analysis and Results](#statistical-theoretical-analysis-and-results)\n",
    "- [Visual Analysis and Results](#visual-analysis-and-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical, Theoretical Analysis and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter names\n",
    "param_names_4 = ['c_1', 'c_2', 'P_const', 'epsilon']\n",
    "param_names_5 = ['c_1', 'c_2', 'P_0', 'P_1', 'epsilon']\n",
    "\n",
    "# Define a function to calculate the metrics\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    # If true_values is a scalar, convert it to a 1D array of the same length as predicted_values\n",
    "    if np.isscalar(true_values):\n",
    "        true_values = np.full(predicted_values.shape, true_values)\n",
    "    \n",
    "    # Calculate the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(true_values, predicted_values)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    \n",
    "    return mse, mae\n",
    "\n",
    "# Get the true parameters\n",
    "true_parameters_4 = theta_true_4.numpy()\n",
    "true_parameters_5 = theta_true_5.numpy()\n",
    "\n",
    "# Get the model predictions\n",
    "predicted_values_4_snpe = posterior_4_snpe.sample((10000,), x=default_observation_4, show_progress_bars=False).numpy()\n",
    "predicted_values_5_snpe = posterior_5_snpe.sample((10000,), x=default_observation_5, show_progress_bars=False).numpy()\n",
    "predicted_values_4_snle = posterior_4_snle.sample((10000,), x=default_observation_4, show_progress_bars=False).numpy()\n",
    "predicted_values_5_snle = posterior_5_snle.sample((10000,), x=default_observation_5, show_progress_bars=False).numpy()\n",
    "predicted_values_4_snre = posterior_4_snre.sample((10000,), x=default_observation_4, show_progress_bars=False).numpy()\n",
    "predicted_values_5_snre = posterior_5_snre.sample((10000,), x=default_observation_5, show_progress_bars=False).numpy()\n",
    "\n",
    "# Initialize empty dataframes for each model and inference method\n",
    "errors_snpe_4 = pd.DataFrame(columns=param_names_4, index=['MSE', 'MAE'])\n",
    "errors_snpe_5 = pd.DataFrame(columns=param_names_5, index=['MSE', 'MAE'])\n",
    "errors_snle_4 = pd.DataFrame(columns=param_names_4, index=['MSE', 'MAE'])\n",
    "errors_snle_5 = pd.DataFrame(columns=param_names_5, index=['MSE', 'MAE'])\n",
    "errors_snre_4 = pd.DataFrame(columns=param_names_4, index=['MSE', 'MAE'])\n",
    "errors_snre_5 = pd.DataFrame(columns=param_names_5, index=['MSE', 'MAE'])\n",
    "\n",
    "# Calculate and store the MSE and MAE for each parameter of model 4 for SNPE\n",
    "for i in range(len(param_names_4)):\n",
    "    mse, mae = calculate_metrics(true_parameters_4[i], predicted_values_4_snpe[:, i])\n",
    "    errors_snpe_4.loc['MSE', param_names_4[i]] = mse\n",
    "    errors_snpe_4.loc['MAE', param_names_4[i]] = mae\n",
    "\n",
    "    mse, mae = calculate_metrics(true_parameters_4[i], predicted_values_4_snre[:, i])\n",
    "    errors_snre_4.loc['MSE', param_names_4[i]] = mse\n",
    "    errors_snre_4.loc['MAE', param_names_4[i]] = mae\n",
    "\n",
    "    mse, mae = calculate_metrics(true_parameters_4[i], predicted_values_4_snle[:, i])\n",
    "    errors_snle_4.loc['MSE', param_names_4[i]] = mse\n",
    "    errors_snle_4.loc['MAE', param_names_4[i]] = mae\n",
    "\n",
    "# Calculate and store the MSE and MAE for each parameter of model 5 for SNPE\n",
    "for i in range(len(param_names_5)):\n",
    "    mse, mae = calculate_metrics(true_parameters_5[i], predicted_values_5_snpe[:, i])\n",
    "    errors_snpe_5.loc['MSE', param_names_5[i]] = mse\n",
    "    errors_snpe_5.loc['MAE', param_names_5[i]] = mae\n",
    "\n",
    "    mse, mae = calculate_metrics(true_parameters_5[i], predicted_values_5_snre[:, i])\n",
    "    errors_snre_5.loc['MSE', param_names_5[i]] = mse\n",
    "    errors_snre_5.loc['MAE', param_names_5[i]] = mae\n",
    "\n",
    "    mse, mae = calculate_metrics(true_parameters_5[i], predicted_values_5_snle[:, i])\n",
    "    errors_snle_5.loc['MSE', param_names_5[i]] = mse\n",
    "    errors_snle_5.loc['MAE', param_names_5[i]] = mae\n",
    "\n",
    "# Define the directory\n",
    "directory = \"../../../results/synthetic_data/tables\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "errors_snpe_4.to_csv(os.path.join(directory, \"errors_snpe_4.csv\"))\n",
    "errors_snpe_5.to_csv(os.path.join(directory, \"errors_snpe_5.csv\"))\n",
    "errors_snle_4.to_csv(os.path.join(directory, \"errors_snle_4.csv\"))\n",
    "errors_snle_5.to_csv(os.path.join(directory, \"errors_snle_5.csv\"))\n",
    "errors_snre_4.to_csv(os.path.join(directory, \"errors_snre_4.csv\"))\n",
    "errors_snre_5.to_csv(os.path.join(directory, \"errors_snre_5.csv\"))\n",
    "\n",
    "# Print the tables in a 2x3 grid\n",
    "print(\"Error Tables:\")\n",
    "print(\"SNPE Model (4 Parameters):\")\n",
    "print(errors_snpe_4)\n",
    "print(\"\\nSNPE Model (5 Parameters):\")\n",
    "print(errors_snpe_5)\n",
    "print(\"\\nSNLE Model (4 Parameters):\")\n",
    "print(errors_snle_4)\n",
    "print(\"\\nSNLE Model (5 Parameters):\")\n",
    "print(errors_snle_5)\n",
    "print(\"\\nSNRE Model (4 Parameters):\")\n",
    "print(errors_snre_4)\n",
    "print(\"\\nSNRE Model (5 Parameters):\")\n",
    "print(errors_snre_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Analysis and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior_4_snpe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Call the function for SNPE\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m plot_posteriors(\u001b[43mposterior_4_snpe\u001b[49m, posterior_5_snpe, theta_true_4, theta_true_5, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNPE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Call the function for SNRE\u001b[39;00m\n\u001b[1;32m     55\u001b[0m plot_posteriors(posterior_4_snre, posterior_5_snre, theta_true_4, theta_true_5, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNRE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior_4_snpe' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_posteriors(posterior_4, posterior_5, theta_true_4, theta_true_5, model_name, num_samples=1000):\n",
    "    # Parameter names\n",
    "    param_names_4 = ['c_1', 'c_2', 'P_const', 'epsilon']\n",
    "    param_names_5 = ['c_1', 'c_2', 'P_0', 'P_1', 'epsilon']\n",
    "\n",
    "    # Parameter boundaries\n",
    "    bounds_4 = [[0.1, 1.0], [0.1, 1.0], [0.01, 0.5], [0.01, 0.1]]\n",
    "    bounds_5 = [[0.1, 10.0], [1.0, 100.0], [0.1, 10.0], [40.0, 70.0], [0.1, 10.0]]\n",
    "\n",
    "    # Sample from the posteriors\n",
    "    samples_4 = posterior_4.sample((num_samples,), show_progress_bars=False)\n",
    "    samples_5 = posterior_5.sample((num_samples,), show_progress_bars=False)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "    # Plot the first posterior\n",
    "    for i, param_name in enumerate(param_names_4):\n",
    "        axs[0, i].hist(samples_4[:, i], bins=30, density=True, label=f'Posterior {param_name}', range=bounds_4[i])\n",
    "        axs[0, i].axvline(theta_true_4[i].item(), color='r', linestyle='dashed', linewidth=2, label=f'True {param_name}')\n",
    "        axs[0, i].legend()\n",
    "    axs[0, 0].set_title('swing4', loc='left')\n",
    "\n",
    "    # Remove unused subplot\n",
    "    fig.delaxes(axs[0, 4])\n",
    "\n",
    "    # Plot the second posterior\n",
    "    for i, param_name in enumerate(param_names_5):\n",
    "        axs[1, i].hist(samples_5[:, i], bins=30, density=True, label=f'Posterior {param_name}', range=bounds_5[i])\n",
    "        axs[1, i].axvline(theta_true_5[i].item(), color='r', linestyle='dashed', linewidth=2, label=f'True {param_name}')\n",
    "        axs[1, i].legend()\n",
    "    axs[1, 0].set_title('swing5', loc='left')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add labels to the plot\n",
    "    fig.text(0, 1, 'Parameter Value', ha='center', va='center')\n",
    "    fig.text(0, 1, 'Density', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "    # Define the directory and filename\n",
    "    directory = \"../../../results/synthetic_data/plots\"\n",
    "    filename = f\"posteriors_{model_name.lower()}.pdf\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(directory, filename))\n",
    "\n",
    "# Call the function for SNPE\n",
    "plot_posteriors(posterior_4_snpe, posterior_5_snpe, theta_true_4, theta_true_5, \"SNPE\")\n",
    "\n",
    "# Call the function for SNRE\n",
    "plot_posteriors(posterior_4_snre, posterior_5_snre, theta_true_4, theta_true_5, \"SNRE\")\n",
    "\n",
    "# Call the function for SNLE\n",
    "plot_posteriors(posterior_4_snle, posterior_5_snle, theta_true_4, theta_true_5, \"SNLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
